## Tokenization

- Tokenization is the process in which you transform a stream of characters into a meaningful array of tokens.

```bash

input: let nums = [A,20,30]

output: LET|SYMBOL|EQ|BRACKET|SYMBOL|...

```

***AST*** : Abstract Syntax Tree(AST) is a data-structure which represents the program's structure. AST's are easy to traverse and have many uses.
